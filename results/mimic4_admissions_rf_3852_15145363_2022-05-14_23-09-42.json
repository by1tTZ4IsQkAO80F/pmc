{
    "dataset": "data/mimic4_admissions.csv",
    "algorithm": "rf",
    "params": {
        "colsample_bynode": 0.8,
        "learning_rate": 1,
        "reg_lambda": 1e-05,
        "subsample": 0.8,
        "use_label_encoder": false,
        "objective": "binary:logistic",
        "base_score": 0.5,
        "booster": "gbtree",
        "colsample_bylevel": 1,
        "colsample_bytree": 1,
        "gamma": 0.1,
        "gpu_id": -1,
        "importance_type": "gain",
        "interaction_constraints": "",
        "max_delta_step": 0,
        "max_depth": 6,
        "min_child_weight": 1,
        "missing": NaN,
        "monotone_constraints": "()",
        "n_estimators": 100,
        "n_jobs": 1,
        "num_parallel_tree": 100,
        "random_state": 3852,
        "reg_alpha": 0,
        "scale_pos_weight": 1,
        "tree_method": "exact",
        "validate_parameters": 1,
        "verbosity": null,
        "eval_metric": "logloss"
    },
    "process_time": 13.098183696,
    "time_time": 13.115398645401001,
    "random_state": 3852,
    "alpha": 0.05,
    "n_bins": 10,
    "gamma": 0.1,
    "rho": 0.1,
    "roc_auc_train": 0.8726378195862856,
    "auprc_train": 0.7682557220587879,
    "accuracy_train": 0.8152416071291388,
    "MC_loss_train": 0.12464811322615321,
    "PMC_loss_train": 1.0727886989445028,
    "DC_loss_train": 0.3435443932492608,
    "roc_auc_test": 0.8661555666682901,
    "auprc_test": 0.7648147938935212,
    "accuracy_test": 0.8105597935055656,
    "MC_loss_test": 0.14854983715783981,
    "PMC_loss_test": 1.0605103659701411,
    "DC_loss_test": 0.4452590328650825,
    "feature_importances_": {
        "temperature": 0.017348283901810646,
        "heartrate": 0.004492388106882572,
        "resprate": 0.025231068953871727,
        "o2sat": 0.04839051887392998,
        "sbp": 0.015330388210713863,
        "dbp": 0.0089636892080307,
        "pain": 0.00223167915828526,
        "acuity": 0.40590900182724,
        "insurance": 0.009482025168836117,
        "language": 0.0,
        "marital_status": 0.00482473149895668,
        "ethnicity": 0.025175830349326134,
        "gender": 0.01775071583688259,
        "anchor_year_group": 0.14219093322753906,
        "prev_visit": 0.20510730147361755,
        "prev_adm": 0.06757146120071411
    }
}